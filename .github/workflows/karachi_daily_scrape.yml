name: OLX Karachi Daily Scraper

on:
  schedule:
    # 5:00 AM UTC = 10:00 AM Pakistan Time (Separated by 1 hour from Lahore job)
    - cron: '0 5 * * *'
  # Allow manual trigger
  workflow_dispatch:

jobs:
  scrape-and-update-karachi:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Google Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Create Auth Config Files
        # Use single quotes to prevent bash from stripping quotes
        run: |
          mkdir -p config
          echo '${{ secrets.GOOGLE_CLIENT_SECRET }}' > config/client_secret.json
          echo '${{ secrets.GOOGLE_TOKEN_JSON }}' > config/google_token.json

      - name: Run Scraper (Karachi)
        env:
          # Configuration: Karachi Specific
          MAX_PAGES: 3
          MAX_LISTINGS: 30
          LOCATIONS: "karachi"
          
          # Secrets - Mapping KARACHI_SHEET_ID secret to GOOGLE_SHEET_ID env var
          GOOGLE_SHEET_ID: ${{ secrets.KARACHI_SHEET_ID }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          CI: true
        run: |
          python run_batch.py

      - name: Upload Artifacts (Optional)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-output-karachi
          path: output/
          retention-days: 7
