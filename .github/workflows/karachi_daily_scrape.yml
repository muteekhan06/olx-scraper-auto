name: OLX Karachi Daily Scraper

on:
  schedule:
    # 4:37 AM UTC = 9:37 AM Pakistan Time
    # Minute 37 is chosen to avoid congestion and separate it from the Lahore job
    - cron: '37 4 * * *'
  # Allow manual trigger
  workflow_dispatch:

jobs:
  scrape-and-update-karachi:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Google Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Create Auth Config Files
        # Use single quotes to prevent bash from stripping quotes
        run: |
          mkdir -p config
          echo '${{ secrets.GOOGLE_CLIENT_SECRET }}' > config/client_secret.json
          echo '${{ secrets.GOOGLE_TOKEN_JSON }}' > config/google_token.json

      - name: Run Scraper (Karachi)
        env:
          # Configuration: Karachi Specific
          MAX_PAGES: 2
          MAX_LISTINGS: 15
          LOCATIONS: "karachi"
          
          # Secrets - Mapping KARACHI_SHEET_ID secret to GOOGLE_SHEET_ID env var
          GOOGLE_SHEET_ID: ${{ secrets.KARACHI_SHEET_ID }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          CI: true
        run: |
          python run_batch.py

      - name: Upload Artifacts (Optional)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-output-karachi
          path: output/
          retention-days: 7
